{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: diffusers 0.25.0.dev0\n",
      "Uninstalling diffusers-0.25.0.dev0:\n",
      "  Successfully uninstalled diffusers-0.25.0.dev0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting git+https://github.com/neverix/diffusers@patch-4\n",
      "  Cloning https://github.com/neverix/diffusers (to revision patch-4) to /tmp/pip-req-build-ncqqvq6c\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/neverix/diffusers /tmp/pip-req-build-ncqqvq6c\n",
      "  Running command git checkout -b patch-4 --track origin/patch-4\n",
      "  Switched to a new branch 'patch-4'\n",
      "  Branch 'patch-4' set up to track remote branch 'patch-4' from 'origin'.\n",
      "  Resolved https://github.com/neverix/diffusers to commit 943d95c2eb53dfc20ac1185d73d61fe976119725\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata in /home/neverix/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from diffusers==0.25.0.dev0) (6.8.0)\n",
      "Requirement already satisfied: filelock in /home/neverix/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from diffusers==0.25.0.dev0) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in /home/neverix/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from diffusers==0.25.0.dev0) (0.19.4)\n",
      "Requirement already satisfied: numpy in /home/neverix/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from diffusers==0.25.0.dev0) (1.26.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/neverix/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from diffusers==0.25.0.dev0) (2023.10.3)\n",
      "Requirement already satisfied: requests in /home/neverix/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from diffusers==0.25.0.dev0) (2.31.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/neverix/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from diffusers==0.25.0.dev0) (0.4.0)\n",
      "Requirement already satisfied: Pillow in /home/neverix/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from diffusers==0.25.0.dev0) (10.1.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/neverix/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from huggingface-hub>=0.19.4->diffusers==0.25.0.dev0) (2023.10.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/neverix/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from huggingface-hub>=0.19.4->diffusers==0.25.0.dev0) (4.66.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/neverix/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from huggingface-hub>=0.19.4->diffusers==0.25.0.dev0) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/neverix/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from huggingface-hub>=0.19.4->diffusers==0.25.0.dev0) (4.8.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/neverix/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from huggingface-hub>=0.19.4->diffusers==0.25.0.dev0) (23.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/neverix/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from importlib-metadata->diffusers==0.25.0.dev0) (3.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/neverix/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from requests->diffusers==0.25.0.dev0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/neverix/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from requests->diffusers==0.25.0.dev0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/neverix/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from requests->diffusers==0.25.0.dev0) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/neverix/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from requests->diffusers==0.25.0.dev0) (2023.7.22)\n",
      "Building wheels for collected packages: diffusers\n",
      "  Building wheel for diffusers (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for diffusers: filename=diffusers-0.25.0.dev0-py3-none-any.whl size=1767474 sha256=f0973a3b790535df7ae701f95eb81497c8b3d3ee612834093f34b8ca57c16185\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-kzrz83ab/wheels/45/28/76/384ab6bfc6758699d062ce78fba8e9905f5cd81e08e64d6076\n",
      "Successfully built diffusers\n",
      "Installing collected packages: diffusers\n",
      "Successfully installed diffusers-0.25.0.dev0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip uninstall --yes diffusers\n",
    "%pip install git+https://github.com/neverix/diffusers@patch-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ~/.cache/huggingface/hub\n",
    "# !rm -rf cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'stable-diffusion-xl-base-1.0' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "# !mkdir -p cache\n",
    "# !cd cache && GIT_LFS_SKIP_SMUDGE=1 git clone https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0 --depth=1\n",
    "# !cd cache/stable-diffusion-xl-base-1.0 && git lfs pull --include '*.msgpack' && git lfs pull --include '*.model' && git lfs pull --include '*.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neverix/.pyenv/versions/3.12.0/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Fetching 18 files: 100%|██████████| 18/18 [00:00<00:00, 78073.91it/s]\n"
     ]
    }
   ],
   "source": [
    "from diffusers import FlaxStableDiffusionXLPipeline\n",
    "import jax.numpy as jnp\n",
    "\n",
    "\n",
    "dtype = jnp.bfloat16\n",
    "pipe, params = FlaxStableDiffusionXLPipeline.from_pretrained(\n",
    "    # \"nev/lcm-sdxl-flax\",\n",
    "    # \"nev/lcm-sdxl-pt\",\n",
    "    \"nev/sdxl-turbo-pt\",\n",
    "    # \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
    "    # \"cache/stable-diffusion-xl-base-1.0\",\n",
    "    # \"pcuenq/stable-diffusion-xl-base-1.0-flax\",\n",
    "    # \"stabilityai/sdxl-turbo\",\n",
    "    from_pt=True,\n",
    "    dtype=jnp.float32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TpuDevice(id=0, process_index=0, coords=(0,0,0), core_on_chip=0), TpuDevice(id=1, process_index=0, coords=(0,0,0), core_on_chip=1), TpuDevice(id=2, process_index=0, coords=(1,0,0), core_on_chip=0), TpuDevice(id=3, process_index=0, coords=(1,0,0), core_on_chip=1), TpuDevice(id=4, process_index=0, coords=(0,1,0), core_on_chip=0), TpuDevice(id=5, process_index=0, coords=(0,1,0), core_on_chip=1), TpuDevice(id=6, process_index=0, coords=(1,1,0), core_on_chip=0), TpuDevice(id=7, process_index=0, coords=(1,1,0), core_on_chip=1)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import jax\n",
    "print(jax.devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['text_encoder', 'text_encoder_2', 'unet', 'vae', 'scheduler'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler_state = params.pop(\"scheduler\")\n",
    "vae_state = params.pop(\"vae\")\n",
    "params = jax.tree_util.tree_map(lambda x: x.astype(dtype), params)\n",
    "params[\"scheduler\"] = scheduler_state\n",
    "params[\"vae\"] = vae_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flax.training.common_utils import shard\n",
    "from flax.jax_utils import replicate\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "p_params = replicate(params)\n",
    "\n",
    "def create_key(seed=0):\n",
    "    return jax.random.PRNGKey(seed)\n",
    "\n",
    "rng = create_key(0)\n",
    "rng = jax.random.split(rng, jax.device_count())\n",
    "\n",
    "do_jit = True\n",
    "\n",
    "# def generate(prompt_ids, neg_prompt_ids):\n",
    "#     images = pipe(\n",
    "#         prompt_ids if do_jit else prompt_ids[0],\n",
    "#         p_params if do_jit else params,\n",
    "#         rng if do_jit else rng[0],\n",
    "#         num_inference_steps=1,\n",
    "#         # neg_prompt_ids=neg_prompt_ids if do_jit else neg_prompt_ids[0],\n",
    "#         guidance_scale = 1.0,\n",
    "#         jit=do_jit,\n",
    "#     ).images\n",
    "#     images = images.reshape((images.shape[0] * images.shape[1], ) + images.shape[-3:])\n",
    "#     return pipe.numpy_to_pil(np.array(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_per_device = 1\n",
    "\n",
    "prompt = \"a cat\"\n",
    "prompts = [prompt] * jax.device_count() * imgs_per_device\n",
    "prompt_ids = pipe.prepare_inputs(prompts)\n",
    "prompt_ids = shard(prompt_ids)\n",
    "\n",
    "# neg_prompt = \"misshapen\"\n",
    "# neg_prompts = [neg_prompt] * jax.device_count() * imgs_per_device\n",
    "# neg_prompt_ids = pipe.prepare_inputs(neg_prompts)\n",
    "# neg_prompt_ids = shard(neg_prompt_ids)\n",
    "\n",
    "# for u in generate(prompt_ids, neg_prompt_ids):\n",
    "#     display(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_embeds, pooled_embeds = jax.vmap(pipe.get_embeddings, in_axes=(0, None))(prompt_ids, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width = 512, 512\n",
    "add_time_ids = pipe._get_add_time_ids(\n",
    "    (height, width), (0, 0), (height, width), prompt_embeds.shape[0], dtype=prompt_embeds.dtype\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = prompt_embeds.shape[0]\n",
    "latents_shape = (\n",
    "    batch_size,\n",
    "    pipe.unet.config.in_channels,\n",
    "    height // pipe.vae_scale_factor,\n",
    "    width // pipe.vae_scale_factor,\n",
    ")\n",
    "latents = jax.vmap(lambda x: jax.random.normal(x, shape=latents_shape, dtype=jnp.float32))(rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "XlaRuntimeError",
     "evalue": "RESOURCE_EXHAUSTED: Error allocating device buffer: Attempting to allocate 2.50G. That was not possible. There are 661.25M free.; (0x0x0_HBM0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXlaRuntimeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m/home/neverix/misgen/experiment_turbo.ipynb Cell 14\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B34.91.163.77/home/neverix/misgen/experiment_turbo.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m added_cond_kwargs \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mtext_embeds\u001b[39m\u001b[39m\"\u001b[39m: pooled_embeds, \u001b[39m\"\u001b[39m\u001b[39mtime_ids\u001b[39m\u001b[39m\"\u001b[39m: add_time_ids}\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B34.91.163.77/home/neverix/misgen/experiment_turbo.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m noise_pred \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39;49mvmap(pipe\u001b[39m.\u001b[39;49munet\u001b[39m.\u001b[39;49mapply, in_axes\u001b[39m=\u001b[39;49m(\u001b[39m0\u001b[39;49m, \u001b[39m0\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m, \u001b[39m0\u001b[39;49m, \u001b[39m0\u001b[39;49m))(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B34.91.163.77/home/neverix/misgen/experiment_turbo.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     {\u001b[39m\"\u001b[39;49m\u001b[39mparams\u001b[39;49m\u001b[39m\"\u001b[39;49m: p_params[\u001b[39m\"\u001b[39;49m\u001b[39munet\u001b[39;49m\u001b[39m\"\u001b[39;49m]},\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B34.91.163.77/home/neverix/misgen/experiment_turbo.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     jnp\u001b[39m.\u001b[39;49marray(latents),\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B34.91.163.77/home/neverix/misgen/experiment_turbo.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     jnp\u001b[39m.\u001b[39;49marray(pipe\u001b[39m.\u001b[39;49mscheduler\u001b[39m.\u001b[39;49mconfig\u001b[39m.\u001b[39;49mnum_train_timesteps \u001b[39m-\u001b[39;49m \u001b[39m1\u001b[39;49m, dtype\u001b[39m=\u001b[39;49mjnp\u001b[39m.\u001b[39;49mint32),\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B34.91.163.77/home/neverix/misgen/experiment_turbo.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     prompt_embeds,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B34.91.163.77/home/neverix/misgen/experiment_turbo.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     added_cond_kwargs,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B34.91.163.77/home/neverix/misgen/experiment_turbo.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m )\u001b[39m.\u001b[39msample\n",
      "    \u001b[0;31m[... skipping hidden 9 frame]\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/lib/python3.12/site-packages/diffusers/models/unet_2d_condition_flax.py:398\u001b[0m, in \u001b[0;36mFlaxUNet2DConditionModel.__call__\u001b[0;34m(self, sample, timesteps, encoder_hidden_states, added_cond_kwargs, down_block_additional_residuals, mid_block_additional_residual, return_dict, train)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[39mfor\u001b[39;00m down_block \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdown_blocks:\n\u001b[1;32m    397\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(down_block, FlaxCrossAttnDownBlock2D):\n\u001b[0;32m--> 398\u001b[0m         sample, res_samples \u001b[39m=\u001b[39m down_block(sample, t_emb, encoder_hidden_states, deterministic\u001b[39m=\u001b[39;49m\u001b[39mnot\u001b[39;49;00m train)\n\u001b[1;32m    399\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    400\u001b[0m         sample, res_samples \u001b[39m=\u001b[39m down_block(sample, t_emb, deterministic\u001b[39m=\u001b[39m\u001b[39mnot\u001b[39;00m train)\n",
      "    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/lib/python3.12/site-packages/diffusers/models/unet_2d_blocks_flax.py:101\u001b[0m, in \u001b[0;36mFlaxCrossAttnDownBlock2D.__call__\u001b[0;34m(self, hidden_states, temb, encoder_hidden_states, deterministic)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[39mfor\u001b[39;00m resnet, attn \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresnets, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattentions):\n\u001b[1;32m    100\u001b[0m     hidden_states \u001b[39m=\u001b[39m resnet(hidden_states, temb, deterministic\u001b[39m=\u001b[39mdeterministic)\n\u001b[0;32m--> 101\u001b[0m     hidden_states \u001b[39m=\u001b[39m attn(hidden_states, encoder_hidden_states, deterministic\u001b[39m=\u001b[39;49mdeterministic)\n\u001b[1;32m    102\u001b[0m     output_states \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (hidden_states,)\n\u001b[1;32m    104\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_downsample:\n",
      "    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/lib/python3.12/site-packages/diffusers/models/attention_flax.py:421\u001b[0m, in \u001b[0;36mFlaxTransformer2DModel.__call__\u001b[0;34m(self, hidden_states, context, deterministic)\u001b[0m\n\u001b[1;32m    418\u001b[0m     hidden_states \u001b[39m=\u001b[39m hidden_states\u001b[39m.\u001b[39mreshape(batch, height \u001b[39m*\u001b[39m width, channels)\n\u001b[1;32m    420\u001b[0m \u001b[39mfor\u001b[39;00m transformer_block \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransformer_blocks:\n\u001b[0;32m--> 421\u001b[0m     hidden_states \u001b[39m=\u001b[39m transformer_block(hidden_states, context, deterministic\u001b[39m=\u001b[39;49mdeterministic)\n\u001b[1;32m    423\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_linear_projection:\n\u001b[1;32m    424\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproj_out(hidden_states)\n",
      "    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/lib/python3.12/site-packages/diffusers/models/attention_flax.py:312\u001b[0m, in \u001b[0;36mFlaxBasicTransformerBlock.__call__\u001b[0;34m(self, hidden_states, context, deterministic)\u001b[0m\n\u001b[1;32m    310\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattn1(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm1(hidden_states), context, deterministic\u001b[39m=\u001b[39mdeterministic)\n\u001b[1;32m    311\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 312\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattn1(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnorm1(hidden_states), deterministic\u001b[39m=\u001b[39;49mdeterministic)\n\u001b[1;32m    313\u001b[0m hidden_states \u001b[39m=\u001b[39m hidden_states \u001b[39m+\u001b[39m residual\n\u001b[1;32m    315\u001b[0m \u001b[39m# cross attention\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/lib/python3.12/site-packages/diffusers/models/attention_flax.py:228\u001b[0m, in \u001b[0;36mFlaxAttention.__call__\u001b[0;34m(self, hidden_states, context, deterministic)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    226\u001b[0m     attention_scores \u001b[39m=\u001b[39m jnp\u001b[39m.\u001b[39meinsum(\u001b[39m\"\u001b[39m\u001b[39mb i d, b j d->b i j\u001b[39m\u001b[39m\"\u001b[39m, query_states, key_states)\n\u001b[0;32m--> 228\u001b[0m attention_scores \u001b[39m=\u001b[39m attention_scores \u001b[39m*\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscale\n\u001b[1;32m    229\u001b[0m attention_probs \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39msoftmax(attention_scores, axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msplit_head_dim \u001b[39melse\u001b[39;00m \u001b[39m2\u001b[39m)\n\u001b[1;32m    231\u001b[0m \u001b[39m# attend to values\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/lib/python3.12/site-packages/jax/_src/numpy/array_methods.py:728\u001b[0m, in \u001b[0;36m_forward_operator_to_aval.<locals>.op\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mop\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs):\n\u001b[0;32m--> 728\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maval, \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m_\u001b[39;49m\u001b[39m{\u001b[39;49;00mname\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m)(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/lib/python3.12/site-packages/jax/_src/numpy/array_methods.py:256\u001b[0m, in \u001b[0;36m_defer_to_unrecognized_arg.<locals>.deferring_binary_op\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    254\u001b[0m args \u001b[39m=\u001b[39m (other, \u001b[39mself\u001b[39m) \u001b[39mif\u001b[39;00m swap \u001b[39melse\u001b[39;00m (\u001b[39mself\u001b[39m, other)\n\u001b[1;32m    255\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(other, _accepted_binop_types):\n\u001b[0;32m--> 256\u001b[0m   \u001b[39mreturn\u001b[39;00m binary_op(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    257\u001b[0m \u001b[39m# Note: don't use isinstance here, because we don't want to raise for\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[39m# subclasses, e.g. NamedTuple objects that may override operators.\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(other) \u001b[39min\u001b[39;00m _rejected_binop_types:\n",
      "    \u001b[0;31m[... skipping hidden 14 frame]\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/lib/python3.12/site-packages/jax/_src/interpreters/pxla.py:1152\u001b[0m, in \u001b[0;36mExecuteReplicated.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1150\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_token_bufs(result_token_bufs, sharded_runtime_token)\n\u001b[1;32m   1151\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1152\u001b[0m   results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mxla_executable\u001b[39m.\u001b[39;49mexecute_sharded(input_bufs)\n\u001b[1;32m   1153\u001b[0m \u001b[39mif\u001b[39;00m dispatch\u001b[39m.\u001b[39mneeds_check_special():\n\u001b[1;32m   1154\u001b[0m   out_arrays \u001b[39m=\u001b[39m results\u001b[39m.\u001b[39mdisassemble_into_single_device_arrays()\n",
      "\u001b[0;31mXlaRuntimeError\u001b[0m: RESOURCE_EXHAUSTED: Error allocating device buffer: Attempting to allocate 2.50G. That was not possible. There are 661.25M free.; (0x0x0_HBM0)"
     ]
    }
   ],
   "source": [
    "added_cond_kwargs = {\"text_embeds\": pooled_embeds, \"time_ids\": add_time_ids}\n",
    "noise_pred = jax.pmap(pipe.unet.apply, in_axes=(0, 0, None, 0, 0))(\n",
    "    {\"params\": p_params[\"unet\"]},\n",
    "    jnp.array(latents),\n",
    "    jnp.array(pipe.scheduler.config.num_train_timesteps - 1, dtype=jnp.int32),\n",
    "    prompt_embeds,\n",
    "    added_cond_kwargs,\n",
    ").sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'noise_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/neverix/misgen/experiment_turbo.ipynb Cell 15\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B34.91.163.77/home/neverix/misgen/experiment_turbo.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m noise_pred\n",
      "\u001b[0;31mNameError\u001b[0m: name 'noise_pred' is not defined"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(noise_pred[0, 0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  * scheduler_state.init_noise_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    def __call__(\n",
      "        self,\n",
      "        prompt_ids: jax.Array,\n",
      "        params: Union[Dict, FrozenDict],\n",
      "        prng_seed: jax.Array,\n",
      "        num_inference_steps: int = 50,\n",
      "        guidance_scale: Union[float, jax.Array] = 7.5,\n",
      "        height: Optional[int] = None,\n",
      "        width: Optional[int] = None,\n",
      "        latents: jnp.array = None,\n",
      "        neg_prompt_ids: jnp.array = None,\n",
      "        return_dict: bool = True,\n",
      "        output_type: str = None,\n",
      "        jit: bool = False,\n",
      "    ):\n",
      "        # 0. Default height and width to unet\n",
      "        height = height or self.unet.config.sample_size * self.vae_scale_factor\n",
      "        width = width or self.unet.config.sample_size * self.vae_scale_factor\n",
      "\n",
      "        if isinstance(guidance_scale, float) and jit:\n",
      "            # Convert to a tensor so each device gets a copy.\n",
      "            guidance_scale = jnp.array([guidance_scale] * prompt_ids.shape[0])\n",
      "            guidance_scale = guidance_scale[:, None]\n",
      "\n",
      "        return_latents = output_type == \"latent\"\n",
      "\n",
      "        if jit:\n",
      "            images = _p_generate(\n",
      "                self,\n",
      "                prompt_ids,\n",
      "                params,\n",
      "                prng_seed,\n",
      "                num_inference_steps,\n",
      "                height,\n",
      "                width,\n",
      "                guidance_scale,\n",
      "                latents,\n",
      "                neg_prompt_ids,\n",
      "                return_latents,\n",
      "            )\n",
      "        else:\n",
      "            images = self._generate(\n",
      "                prompt_ids,\n",
      "                params,\n",
      "                prng_seed,\n",
      "                num_inference_steps,\n",
      "                height,\n",
      "                width,\n",
      "                guidance_scale,\n",
      "                latents,\n",
      "                neg_prompt_ids,\n",
      "                return_latents,\n",
      "            )\n",
      "\n",
      "        if not return_dict:\n",
      "            return (images,)\n",
      "\n",
      "        return FlaxStableDiffusionXLPipelineOutput(images=images)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from inspect import getsource\n",
    "print(getsource(pipe.__call__))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
